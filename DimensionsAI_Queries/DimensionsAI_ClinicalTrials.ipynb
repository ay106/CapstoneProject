{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b479f862",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm as progress\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from plotly.offline import plot\n",
    "import dimcli\n",
    "from dimcli.utils import *\n",
    "import os, sys, time, json\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "import csv\n",
    "from itertools import islice\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580f7c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log into Dimensions\n",
    "#API key is: 9F8D648F0D7E437CB1736BEBDF007F02\n",
    "#!pip install dimcli -U --quiet \n",
    "\n",
    "print(\"==\\nLogging in..\")\n",
    "# https://digital-science.github.io/dimcli/getting-started.html#authentication\n",
    "ENDPOINT = \"https://app.dimensions.ai\"\n",
    "if 'google.colab' in sys.modules:\n",
    "    import getpass\n",
    "    KEY = getpass.getpass(prompt='API Key: ')  \n",
    "    dimcli.login(key=KEY, endpoint=ENDPOINT)\n",
    "else:\n",
    "    KEY = \"9F8D648F0D7E437CB1736BEBDF007F02\"\n",
    "    dimcli.login(key=KEY, endpoint=ENDPOINT)\n",
    "dsl = dimcli.Dsl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a07df5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "singleRead = {}\n",
    "file_path = r'\\Users\\ashle\\OneDrive\\School\\Capstone\\dimensionsAI\\nameOneIDs.csv'\n",
    "with open(file_path, 'r') as csv_file:\n",
    "    # Create a CSV DictReader object\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "\n",
    "    # Iterate through the rows in the CSV file\n",
    "    for row in csv_reader:\n",
    "        # Each row is now a dictionary with column names as keys\n",
    "        singleRead[row['Name']] = ast.literal_eval(row['ID'])\n",
    "        \n",
    "        \n",
    "first_half_items = list(singleRead.items())\n",
    "# Create a new dictionary using the first half items\n",
    "whole_Dict = dict(first_half_items)\n",
    "\n",
    "print(len(whole_Dict))\n",
    "print(whole_Dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530c51c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_Var2 = \"[abstract + acronym + active_years + altmetric + associated_grant_ids + brief_title + category_bra + category_for + category_for_2020 + category_hra + category_hrcs_hc + category_hrcs_rac + category_icrp_cso + category_icrp_ct + category_rcdc + conditions + date + date_inserted + dimensions_url + end_date + funder_countries + funders + gender + id + interventions + investigators + linkout + mesh_terms + phase + publication_ids + publications + registry + research_orgs + researchers + score + start_date + study_arms + study_designs + study_eligibility_criteria + study_maximum_age + study_minimum_age + study_outcome_measures + study_participants + study_type + title]\"\n",
    "\n",
    "# var2 = \"abstract,acronym,active_years,altmetric,associated_grant_ids,brief_title,category_bra,category_for,category_for_2020,category_hra,category_hrcs_hc,category_hrcs_rac,category_icrp_cso,category_icrp_ct,category_rcdc,conditions,date,date_inserted,dimensions_url,end_date,funder_countries,funders,gender,id,interventions,investigators,linkout,mesh_terms,phase,publication_ids,publications,registry,research_orgs,researchers,score,start_date,study_arms,study_designs,study_eligibility_criteria,study_maximum_age,study_minimum_age,study_outcome_measures,study_participants,study_type,title\"\n",
    "# var2 = str(var2.replace(\",\", \" + \"))\n",
    "# search_Var2 = var2\n",
    "# print(var2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87aff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_arms, study_designs, study_eligibility_criteria, study_maximum_age, study_minimum_age, study_outcome_measures, study_participants, study_type\n",
    "# abstract, conditions, gender, linkout, phase registry, category_bra, category_for, category_hra, category_hrcs_hc, category_hrcs_rac, category_icrp_cso, category_icrp_ct, category_rcdc + active_years + id + investigators + title\n",
    "\n",
    "\n",
    "def findby_IdCT(nameDict):\n",
    "    all_CT= {}\n",
    "    count=0\n",
    "    for name, person_id in nameDict.items():\n",
    "        print(person_id[0])        \n",
    "        res = dsl.query_iterative(f\"\"\"search clinical_trials where researchers = \"{person_id[0]}\" return clinical_trials {search_Var2}\"\"\")\n",
    "        number = res.json['_stats']['total_count']\n",
    "        print(f'{person_id[0]} id has {number} clinical trials')\n",
    "        listDict = res.json['clinical_trials']\n",
    "        name_list = []\n",
    "        for ct in listDict:\n",
    "            name_list.append(ct)\n",
    "        \n",
    "        all_CT[name] = name_list\n",
    "        count+=1\n",
    "        print(f'{count}. {name}')\n",
    "  \n",
    "    return all_CT\n",
    "\n",
    "ct = findby_IdCT(whole_Dict) \n",
    "\n",
    "# Specify the file name\n",
    "json_filename = \"all_ClinicalTrials.json\"\n",
    "\n",
    "# Writing the dictionary to a JSON file\n",
    "with open(json_filename, 'w') as json_file:\n",
    "    json.dump(ct, json_file, indent=2)\n",
    "\n",
    "print(f'The data has been written to {json_filename}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
